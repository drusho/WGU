{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Assessement\n",
    "\n",
    "D206 Data Cleaning </br>\n",
    "David Rusho </br>\n",
    "Student ID: 012037553 </br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting missingno\n",
      "  Downloading missingno-0.5.2-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: numpy in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from missingno) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from missingno) (3.8.3)\n",
      "Requirement already satisfied: scipy in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from missingno) (1.12.0)\n",
      "Collecting seaborn (from missingno)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from matplotlib->missingno) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from matplotlib->missingno) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from matplotlib->missingno) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from matplotlib->missingno) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from matplotlib->missingno) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from matplotlib->missingno) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from matplotlib->missingno) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from matplotlib->missingno) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from seaborn->missingno) (2.2.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn->missingno) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn->missingno) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/david/Documents/GitHub/WGU/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n",
      "Downloading missingno-0.5.2-py3-none-any.whl (8.7 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: seaborn, missingno\n",
      "Successfully installed missingno-0.5.2 seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install matplotlib\n",
    "# !pip3 install pandas\n",
    "# !pip3 install prettytable\n",
    "# !pip3 install scipy\n",
    "# !pip3 install missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import prettytable\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CSV into Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaseOrder</th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Interaction</th>\n",
       "      <th>UID</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Job</th>\n",
       "      <th>Children</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Employment</th>\n",
       "      <th>Income</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ReAdmis</th>\n",
       "      <th>VitD_levels</th>\n",
       "      <th>Doc_visits</th>\n",
       "      <th>Full_meals_eaten</th>\n",
       "      <th>VitD_supp</th>\n",
       "      <th>Soft_drink</th>\n",
       "      <th>Initial_admin</th>\n",
       "      <th>HighBlood</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Complication_risk</th>\n",
       "      <th>Overweight</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hyperlipidemia</th>\n",
       "      <th>BackPain</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Allergic_rhinitis</th>\n",
       "      <th>Reflux_esophagitis</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Services</th>\n",
       "      <th>Initial_days</th>\n",
       "      <th>TotalCharge</th>\n",
       "      <th>Additional_charges</th>\n",
       "      <th>Item1</th>\n",
       "      <th>Item2</th>\n",
       "      <th>Item3</th>\n",
       "      <th>Item4</th>\n",
       "      <th>Item5</th>\n",
       "      <th>Item6</th>\n",
       "      <th>Item7</th>\n",
       "      <th>Item8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C412403</td>\n",
       "      <td>8cd49b13-f45a-4b47-a2bd-173ffa932c2f</td>\n",
       "      <td>3a83ddb66e2ae73798bdf1d705dc0932</td>\n",
       "      <td>Eva</td>\n",
       "      <td>AL</td>\n",
       "      <td>Morgan</td>\n",
       "      <td>35621</td>\n",
       "      <td>34.34960</td>\n",
       "      <td>-86.72508</td>\n",
       "      <td>2951</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>Psychologist, sport and exercise</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Some College, Less than 1 Year</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>86575.93</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>17.802330</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emergency Admission</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Blood Work</td>\n",
       "      <td>10.585770</td>\n",
       "      <td>3191.048774</td>\n",
       "      <td>17939.40342</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Z919181</td>\n",
       "      <td>d2450b70-0337-4406-bdbb-bc1037f1734c</td>\n",
       "      <td>176354c5eef714957d486009feabf195</td>\n",
       "      <td>Marianna</td>\n",
       "      <td>FL</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>32446</td>\n",
       "      <td>30.84513</td>\n",
       "      <td>-85.22907</td>\n",
       "      <td>11303</td>\n",
       "      <td>Urban</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>Community development worker</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Some College, 1 or More Years, No Degree</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>46805.99</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>18.994640</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Emergency Admission</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>High</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Intravenous</td>\n",
       "      <td>15.129562</td>\n",
       "      <td>4214.905346</td>\n",
       "      <td>17612.99812</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F995323</td>\n",
       "      <td>a2057123-abf5-4a2c-abad-8ffe33512562</td>\n",
       "      <td>e19a0fa00aeda885b8a436757e889bc9</td>\n",
       "      <td>Sioux Falls</td>\n",
       "      <td>SD</td>\n",
       "      <td>Minnehaha</td>\n",
       "      <td>57110</td>\n",
       "      <td>43.54321</td>\n",
       "      <td>-96.63772</td>\n",
       "      <td>17125</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>Chief Executive Officer</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Some College, 1 or More Years, No Degree</td>\n",
       "      <td>Retired</td>\n",
       "      <td>14370.14</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>17.415889</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Elective Admission</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Blood Work</td>\n",
       "      <td>4.772177</td>\n",
       "      <td>2177.586768</td>\n",
       "      <td>17505.19246</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CaseOrder Customer_id                           Interaction  \\\n",
       "1          1     C412403  8cd49b13-f45a-4b47-a2bd-173ffa932c2f   \n",
       "2          2     Z919181  d2450b70-0337-4406-bdbb-bc1037f1734c   \n",
       "3          3     F995323  a2057123-abf5-4a2c-abad-8ffe33512562   \n",
       "\n",
       "                                UID         City State     County    Zip  \\\n",
       "1  3a83ddb66e2ae73798bdf1d705dc0932          Eva    AL     Morgan  35621   \n",
       "2  176354c5eef714957d486009feabf195     Marianna    FL    Jackson  32446   \n",
       "3  e19a0fa00aeda885b8a436757e889bc9  Sioux Falls    SD  Minnehaha  57110   \n",
       "\n",
       "        Lat       Lng  Population      Area         Timezone  \\\n",
       "1  34.34960 -86.72508        2951  Suburban  America/Chicago   \n",
       "2  30.84513 -85.22907       11303     Urban  America/Chicago   \n",
       "3  43.54321 -96.63772       17125  Suburban  America/Chicago   \n",
       "\n",
       "                                Job  Children   Age  \\\n",
       "1  Psychologist, sport and exercise       1.0  53.0   \n",
       "2      Community development worker       3.0  51.0   \n",
       "3           Chief Executive Officer       3.0  53.0   \n",
       "\n",
       "                                  Education Employment    Income   Marital  \\\n",
       "1            Some College, Less than 1 Year  Full Time  86575.93  Divorced   \n",
       "2  Some College, 1 or More Years, No Degree  Full Time  46805.99   Married   \n",
       "3  Some College, 1 or More Years, No Degree    Retired  14370.14   Widowed   \n",
       "\n",
       "   Gender ReAdmis  VitD_levels  Doc_visits  Full_meals_eaten  VitD_supp  \\\n",
       "1    Male      No    17.802330           6                 0          0   \n",
       "2  Female      No    18.994640           4                 2          1   \n",
       "3  Female      No    17.415889           4                 1          0   \n",
       "\n",
       "  Soft_drink        Initial_admin HighBlood Stroke Complication_risk  \\\n",
       "1        NaN  Emergency Admission       Yes     No            Medium   \n",
       "2         No  Emergency Admission       Yes     No              High   \n",
       "3         No   Elective Admission       Yes     No            Medium   \n",
       "\n",
       "   Overweight Arthritis Diabetes Hyperlipidemia BackPain  Anxiety  \\\n",
       "1         0.0       Yes      Yes             No      Yes      1.0   \n",
       "2         1.0        No       No             No       No      NaN   \n",
       "3         1.0        No      Yes             No       No      NaN   \n",
       "\n",
       "  Allergic_rhinitis Reflux_esophagitis Asthma     Services  Initial_days  \\\n",
       "1               Yes                 No    Yes   Blood Work     10.585770   \n",
       "2                No                Yes     No  Intravenous     15.129562   \n",
       "3                No                 No     No   Blood Work      4.772177   \n",
       "\n",
       "   TotalCharge  Additional_charges  Item1  Item2  Item3  Item4  Item5  Item6  \\\n",
       "1  3191.048774         17939.40342      3      3      2      2      4      3   \n",
       "2  4214.905346         17612.99812      3      4      3      4      4      4   \n",
       "3  2177.586768         17505.19246      2      4      4      4      3      4   \n",
       "\n",
       "   Item7  Item8  \n",
       "1      3      4  \n",
       "2      3      3  \n",
       "3      3      3  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase column display/print range to display all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"/Users/david/Documents/GitHub/WGU/d206 - Data Cleaning/Assessment/Medical Data and Dictionary Files/medical_raw_data.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "# First column of csv is already an index, set Pandas to not create an index  using 'index_col=0'\n",
    "med_df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# print first 3 rows\n",
    "med_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 1 to 10000\n",
      "Data columns (total 52 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   CaseOrder           10000 non-null  int64  \n",
      " 1   Customer_id         10000 non-null  object \n",
      " 2   Interaction         10000 non-null  object \n",
      " 3   UID                 10000 non-null  object \n",
      " 4   City                10000 non-null  object \n",
      " 5   State               10000 non-null  object \n",
      " 6   County              10000 non-null  object \n",
      " 7   Zip                 10000 non-null  int64  \n",
      " 8   Lat                 10000 non-null  float64\n",
      " 9   Lng                 10000 non-null  float64\n",
      " 10  Population          10000 non-null  int64  \n",
      " 11  Area                10000 non-null  object \n",
      " 12  Timezone            10000 non-null  object \n",
      " 13  Job                 10000 non-null  object \n",
      " 14  Children            7412 non-null   float64\n",
      " 15  Age                 7586 non-null   float64\n",
      " 16  Education           10000 non-null  object \n",
      " 17  Employment          10000 non-null  object \n",
      " 18  Income              7536 non-null   float64\n",
      " 19  Marital             10000 non-null  object \n",
      " 20  Gender              10000 non-null  object \n",
      " 21  ReAdmis             10000 non-null  object \n",
      " 22  VitD_levels         10000 non-null  float64\n",
      " 23  Doc_visits          10000 non-null  int64  \n",
      " 24  Full_meals_eaten    10000 non-null  int64  \n",
      " 25  VitD_supp           10000 non-null  int64  \n",
      " 26  Soft_drink          7533 non-null   object \n",
      " 27  Initial_admin       10000 non-null  object \n",
      " 28  HighBlood           10000 non-null  object \n",
      " 29  Stroke              10000 non-null  object \n",
      " 30  Complication_risk   10000 non-null  object \n",
      " 31  Overweight          9018 non-null   float64\n",
      " 32  Arthritis           10000 non-null  object \n",
      " 33  Diabetes            10000 non-null  object \n",
      " 34  Hyperlipidemia      10000 non-null  object \n",
      " 35  BackPain            10000 non-null  object \n",
      " 36  Anxiety             9016 non-null   float64\n",
      " 37  Allergic_rhinitis   10000 non-null  object \n",
      " 38  Reflux_esophagitis  10000 non-null  object \n",
      " 39  Asthma              10000 non-null  object \n",
      " 40  Services            10000 non-null  object \n",
      " 41  Initial_days        8944 non-null   float64\n",
      " 42  TotalCharge         10000 non-null  float64\n",
      " 43  Additional_charges  10000 non-null  float64\n",
      " 44  Item1               10000 non-null  int64  \n",
      " 45  Item2               10000 non-null  int64  \n",
      " 46  Item3               10000 non-null  int64  \n",
      " 47  Item4               10000 non-null  int64  \n",
      " 48  Item5               10000 non-null  int64  \n",
      " 49  Item6               10000 non-null  int64  \n",
      " 50  Item7               10000 non-null  int64  \n",
      " 51  Item8               10000 non-null  int64  \n",
      "dtypes: float64(11), int64(14), object(27)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display dataframe datatypes and other basic info\n",
    "med_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Print Value Counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print value counts\n",
    "def print_counts(data_counts, column_name, max_rows=None):\n",
    "    sorted_counts = data_counts.sort_values(ascending=False)\n",
    "    table = prettytable.PrettyTable([column_name, \"Count\"])  # Create table with headers\n",
    "    if max_rows:\n",
    "        sorted_counts = sorted_counts.head(max_rows)\n",
    "    for value, count in sorted_counts.items():\n",
    "        table.add_row([value, count])\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting and Treat Duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Count\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>duplicates</th>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>False</td>\n",
       "            <td>10000</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------+-------+\n",
       "| duplicates | Count |\n",
       "+------------+-------+\n",
       "|   False    | 10000 |\n",
       "+------------+-------+"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine duplicate count of dataframe\n",
    "# Resource: https://note.nkmk.me/en/python-pandas-duplicated-drop-duplicates/\n",
    "dup_count = med_df.duplicated().value_counts()\n",
    "\n",
    "# value counts of duplicates in descending order\n",
    "print(\"Duplicate Count\")\n",
    "print_counts(dup_count, \"duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Count After Duplicates Dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>duplicates</th>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>False</td>\n",
       "            <td>10000</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------+-------+\n",
       "| duplicates | Count |\n",
       "+------------+-------+\n",
       "|   False    | 10000 |\n",
       "+------------+-------+"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the original dataframe\n",
    "df_dup_drop = med_df.copy()\n",
    "\n",
    "# Determine duplicate count of new dataframe copy\n",
    "# Resource: https://note.nkmk.me/en/python-pandas-duplicated-drop-duplicates/\n",
    "df_dup_drop = med_df.drop_duplicates()\n",
    "dup_count2 = df_dup_drop.duplicated().value_counts()\n",
    "\n",
    "# value counts of duplicates in descending order\n",
    "print(\"Duplicate Count After Duplicates Dropped\")\n",
    "print_counts(dup_count2, \"duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection and Teatment of Missing Values\n",
    "\n",
    "_Missing values are usually represented in a form of Nan or null or None in the dataset_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Nulls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Null Counts by Column Name\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Name</th>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Children</td>\n",
       "            <td>2588</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Soft_drink</td>\n",
       "            <td>2467</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Income</td>\n",
       "            <td>2464</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Age</td>\n",
       "            <td>2414</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Initial_days</td>\n",
       "            <td>1056</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Anxiety</td>\n",
       "            <td>984</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Overweight</td>\n",
       "            <td>982</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Complication_risk</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Arthritis</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Diabetes</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------------------+-------+\n",
       "|        Name       | Count |\n",
       "+-------------------+-------+\n",
       "|      Children     |  2588 |\n",
       "|     Soft_drink    |  2467 |\n",
       "|       Income      |  2464 |\n",
       "|        Age        |  2414 |\n",
       "|    Initial_days   |  1056 |\n",
       "|      Anxiety      |  984  |\n",
       "|     Overweight    |  982  |\n",
       "| Complication_risk |   0   |\n",
       "|     Arthritis     |   0   |\n",
       "|      Diabetes     |   0   |\n",
       "+-------------------+-------+"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count nulls by column\n",
    "df_isnull = df_dup_drop.isnull().sum(axis=0)\n",
    "\n",
    "# value counts of nulls in descending order\n",
    "print(\"Top 10 Null Counts by Column Name\")\n",
    "print_counts(df_isnull, \"Name\", 10)  # .plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Analysis of the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Unique Value Counts\n",
    "\n",
    "**Columns that should have unqie values per row**\n",
    "\n",
    "| name        | requied to be unique | description                                                            |\n",
    "| :---------- | :------------------- | :--------------------------------------------------------------------- |\n",
    "| CaseOrder   | Yes                  | Original index for dataframe                                           |\n",
    "| Customer_id | Yes                  | Unique patient ID                                                      |\n",
    "| Interaction | Yes                  | Unique IDs related to patient transactions, procedures, and admissions |\n",
    "| UID         | Yes                  | Unique IDs related to patient transactions, procedures, and admissions |\n",
    "\n",
    "</br>\n",
    "\n",
    "**Columns that have a high likihood of returning unique values per row**</br>\n",
    "_Not a requirement of the data cleaning process_\n",
    "| name | requied to be unique | description |\n",
    "|:-- |:-- | :-- |\n",
    "|VitD_levels| No | Patient’s vitamin D levels as measured in ng/mL. |\n",
    "|TotalCharge| No | The amount charged to the patient daily. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Name</th>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>CaseOrder</td>\n",
       "            <td>10000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>VitD_levels</td>\n",
       "            <td>10000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Customer_id</td>\n",
       "            <td>10000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>TotalCharge</td>\n",
       "            <td>10000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Interaction</td>\n",
       "            <td>10000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>UID</td>\n",
       "            <td>10000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Initial_days</td>\n",
       "            <td>8944</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Additional_charges</td>\n",
       "            <td>8888</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Zip</td>\n",
       "            <td>8612</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Lng</td>\n",
       "            <td>8601</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Lat</td>\n",
       "            <td>8588</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Income</td>\n",
       "            <td>7531</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>City</td>\n",
       "            <td>6072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Population</td>\n",
       "            <td>5951</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>County</td>\n",
       "            <td>1607</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+--------------------+-------+\n",
       "|        Name        | Count |\n",
       "+--------------------+-------+\n",
       "|     CaseOrder      | 10000 |\n",
       "|    VitD_levels     | 10000 |\n",
       "|    Customer_id     | 10000 |\n",
       "|    TotalCharge     | 10000 |\n",
       "|    Interaction     | 10000 |\n",
       "|        UID         | 10000 |\n",
       "|    Initial_days    |  8944 |\n",
       "| Additional_charges |  8888 |\n",
       "|        Zip         |  8612 |\n",
       "|        Lng         |  8601 |\n",
       "|        Lat         |  8588 |\n",
       "|       Income       |  7531 |\n",
       "|        City        |  6072 |\n",
       "|     Population     |  5951 |\n",
       "|       County       |  1607 |\n",
       "+--------------------+-------+"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify unique values count by all columns\n",
    "\n",
    "# dataframe columns to list\n",
    "df_cols_list = med_df.columns.to_list()\n",
    "\n",
    "# count unique values per column,\n",
    "unique_count = med_df[df_cols_list].nunique()\n",
    "\n",
    "# print table, limit results to top 10\n",
    "create_pt(unique_count, \"Name\", 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify categorical columns values\n",
    "\n",
    "_These columns should return values that are limited in count, and are not unique per row_\n",
    "\n",
    "- Area\n",
    "- Timezone\n",
    "- Education\n",
    "- Employment\n",
    "- Marital\n",
    "- Gender\n",
    "- Initial_admin\n",
    "- Complication_risk\n",
    "- Services\n",
    "- Item1\n",
    "- Item2\n",
    "- Item3\n",
    "- Item4\n",
    "- Item5\n",
    "- Item6\n",
    "- Item7\n",
    "- Item8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for 'Area':\n",
      "+----------+-------+\n",
      "|   Name   | Count |\n",
      "+----------+-------+\n",
      "|  Rural   |  3369 |\n",
      "| Suburban |  3328 |\n",
      "|  Urban   |  3303 |\n",
      "+----------+-------+\n",
      "\n",
      "Value Counts for 'Timezone':\n",
      "+--------------------------------+-------+\n",
      "|              Name              | Count |\n",
      "+--------------------------------+-------+\n",
      "|        America/New_York        |  3889 |\n",
      "|        America/Chicago         |  3771 |\n",
      "|      America/Los_Angeles       |  937  |\n",
      "|         America/Denver         |  612  |\n",
      "|        America/Detroit         |  262  |\n",
      "|  America/Indiana/Indianapolis  |  151  |\n",
      "|        America/Phoenix         |  100  |\n",
      "|         America/Boise          |   86  |\n",
      "|       America/Anchorage        |   50  |\n",
      "|      America/Puerto_Rico       |   43  |\n",
      "|        Pacific/Honolulu        |   34  |\n",
      "|       America/Menominee        |   14  |\n",
      "|          America/Nome          |   12  |\n",
      "|   America/Indiana/Vincennes    |   8   |\n",
      "|  America/Kentucky/Louisville   |   6   |\n",
      "|         America/Sitka          |   6   |\n",
      "|        America/Toronto         |   5   |\n",
      "|    America/Indiana/Marengo     |   3   |\n",
      "|   America/Indiana/Tell_City    |   3   |\n",
      "|  America/North_Dakota/Beulah   |   2   |\n",
      "|        America/Yakutat         |   1   |\n",
      "|    America/Indiana/Winamac     |   1   |\n",
      "|      America/Indiana/Knox      |   1   |\n",
      "| America/North_Dakota/New_Salem |   1   |\n",
      "|     America/Indiana/Vevay      |   1   |\n",
      "|          America/Adak          |   1   |\n",
      "+--------------------------------+-------+\n",
      "\n",
      "Value Counts for 'Education':\n",
      "+------------------------------------------+-------+\n",
      "|                   Name                   | Count |\n",
      "+------------------------------------------+-------+\n",
      "|       Regular High School Diploma        |  2444 |\n",
      "|            Bachelor's Degree             |  1724 |\n",
      "| Some College, 1 or More Years, No Degree |  1484 |\n",
      "|   9th Grade to 12th Grade, No Diploma    |  832  |\n",
      "|            Associate's Degree            |  797  |\n",
      "|             Master's Degree              |  701  |\n",
      "|      Some College, Less than 1 Year      |  642  |\n",
      "|       Nursery School to 8th Grade        |  552  |\n",
      "|      GED or Alternative Credential       |  389  |\n",
      "|        Professional School Degree        |  208  |\n",
      "|          No Schooling Completed          |  133  |\n",
      "|             Doctorate Degree             |   94  |\n",
      "+------------------------------------------+-------+\n",
      "\n",
      "Value Counts for 'Employment':\n",
      "+------------+-------+\n",
      "|    Name    | Count |\n",
      "+------------+-------+\n",
      "| Full Time  |  6029 |\n",
      "|  Student   |  1017 |\n",
      "| Part Time  |  991  |\n",
      "| Unemployed |  983  |\n",
      "|  Retired   |  980  |\n",
      "+------------+-------+\n",
      "\n",
      "Value Counts for 'Marital':\n",
      "+---------------+-------+\n",
      "|      Name     | Count |\n",
      "+---------------+-------+\n",
      "|    Widowed    |  2045 |\n",
      "|    Married    |  2023 |\n",
      "|   Separated   |  1987 |\n",
      "| Never Married |  1984 |\n",
      "|    Divorced   |  1961 |\n",
      "+---------------+-------+\n",
      "\n",
      "Value Counts for 'Gender':\n",
      "+----------------------+-------+\n",
      "|         Name         | Count |\n",
      "+----------------------+-------+\n",
      "|        Female        |  5018 |\n",
      "|         Male         |  4768 |\n",
      "| Prefer not to answer |  214  |\n",
      "+----------------------+-------+\n",
      "\n",
      "Value Counts for 'Initial_admin':\n",
      "+-----------------------+-------+\n",
      "|          Name         | Count |\n",
      "+-----------------------+-------+\n",
      "|  Emergency Admission  |  5060 |\n",
      "|   Elective Admission  |  2504 |\n",
      "| Observation Admission |  2436 |\n",
      "+-----------------------+-------+\n",
      "\n",
      "Value Counts for 'Complication_risk':\n",
      "+--------+-------+\n",
      "|  Name  | Count |\n",
      "+--------+-------+\n",
      "| Medium |  4517 |\n",
      "|  High  |  3358 |\n",
      "|  Low   |  2125 |\n",
      "+--------+-------+\n",
      "\n",
      "Value Counts for 'Services':\n",
      "+-------------+-------+\n",
      "|     Name    | Count |\n",
      "+-------------+-------+\n",
      "|  Blood Work |  5265 |\n",
      "| Intravenous |  3130 |\n",
      "|   CT Scan   |  1225 |\n",
      "|     MRI     |  380  |\n",
      "+-------------+-------+\n",
      "\n",
      "Value Counts for 'Item1':\n",
      "+------+-------+\n",
      "| Name | Count |\n",
      "+------+-------+\n",
      "|  4   |  3455 |\n",
      "|  3   |  3404 |\n",
      "|  5   |  1377 |\n",
      "|  2   |  1315 |\n",
      "|  6   |  225  |\n",
      "|  1   |  213  |\n",
      "|  7   |   10  |\n",
      "|  8   |   1   |\n",
      "+------+-------+\n",
      "\n",
      "Value Counts for 'Item2':\n",
      "+------+-------+\n",
      "| Name | Count |\n",
      "+------+-------+\n",
      "|  3   |  3439 |\n",
      "|  4   |  3351 |\n",
      "|  5   |  1421 |\n",
      "|  2   |  1360 |\n",
      "|  1   |  213  |\n",
      "|  6   |  204  |\n",
      "|  7   |   12  |\n",
      "+------+-------+\n",
      "\n",
      "Value Counts for 'Item3':\n",
      "+------+-------+\n",
      "| Name | Count |\n",
      "+------+-------+\n",
      "|  4   |  3464 |\n",
      "|  3   |  3379 |\n",
      "|  5   |  1358 |\n",
      "|  2   |  1356 |\n",
      "|  6   |  220  |\n",
      "|  1   |  211  |\n",
      "|  7   |   11  |\n",
      "|  8   |   1   |\n",
      "+------+-------+\n",
      "\n",
      "Value Counts for 'Item4':\n",
      "+------+-------+\n",
      "| Name | Count |\n",
      "+------+-------+\n",
      "|  3   |  3422 |\n",
      "|  4   |  3394 |\n",
      "|  5   |  1388 |\n",
      "|  2   |  1346 |\n",
      "|  6   |  231  |\n",
      "|  1   |  207  |\n",
      "|  7   |   12  |\n",
      "+------+-------+\n",
      "\n",
      "Value Counts for 'Item5':\n",
      "+------+-------+\n",
      "| Name | Count |\n",
      "+------+-------+\n",
      "|  4   |  3446 |\n",
      "|  3   |  3423 |\n",
      "|  2   |  1380 |\n",
      "|  5   |  1308 |\n",
      "|  6   |  219  |\n",
      "|  1   |  211  |\n",
      "|  7   |   13  |\n",
      "+------+-------+\n",
      "\n",
      "Value Counts for 'Item6':\n",
      "+------+-------+\n",
      "| Name | Count |\n",
      "+------+-------+\n",
      "|  4   |  3464 |\n",
      "|  3   |  3371 |\n",
      "|  5   |  1403 |\n",
      "|  2   |  1319 |\n",
      "|  6   |  220  |\n",
      "|  1   |  213  |\n",
      "|  7   |   10  |\n",
      "+------+-------+\n",
      "\n",
      "Value Counts for 'Item7':\n",
      "+------+-------+\n",
      "| Name | Count |\n",
      "+------+-------+\n",
      "|  4   |  3487 |\n",
      "|  3   |  3456 |\n",
      "|  2   |  1345 |\n",
      "|  5   |  1274 |\n",
      "|  1   |  215  |\n",
      "|  6   |  212  |\n",
      "|  7   |   11  |\n",
      "+------+-------+\n",
      "\n",
      "Value Counts for 'Item8':\n",
      "+------+-------+\n",
      "| Name | Count |\n",
      "+------+-------+\n",
      "|  3   |  3401 |\n",
      "|  4   |  3337 |\n",
      "|  5   |  1429 |\n",
      "|  2   |  1391 |\n",
      "|  6   |  221  |\n",
      "|  1   |  209  |\n",
      "|  7   |   12  |\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify value counts for all three categorical columns\n",
    "for col in [\n",
    "    \"Area\",\n",
    "    \"Timezone\",\n",
    "    \"Education\",\n",
    "    \"Employment\",\n",
    "    \"Marital\",\n",
    "    \"Gender\",\n",
    "    \"Initial_admin\",\n",
    "    \"Complication_risk\",\n",
    "    \"Services\",\n",
    "    \"Item1\",\n",
    "    \"Item2\",\n",
    "    \"Item3\",\n",
    "    \"Item4\",\n",
    "    \"Item5\",\n",
    "    \"Item6\",\n",
    "    \"Item7\",\n",
    "    \"Item8\",\n",
    "]:\n",
    "    value_counts = med_df[col].value_counts()\n",
    "\n",
    "    print(f\"Value Counts for '{col}':\")\n",
    "    # print(value_counts)\n",
    "    print(create_pt(value_counts, \"Name\"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Area</th>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Rural</td>\n",
       "            <td>3369</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Suburban</td>\n",
       "            <td>3328</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Urban</td>\n",
       "            <td>3303</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------+-------+\n",
       "|   Area   | Count |\n",
       "+----------+-------+\n",
       "|  Rural   |  3369 |\n",
       "| Suburban |  3328 |\n",
       "|  Urban   |  3303 |\n",
       "+----------+-------+"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print value counts for Area column\n",
    "area_counts = med_df[\"Area\"].value_counts()\n",
    "create_pt(area_counts, \"Area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Timezone</th>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>America/New_York</td>\n",
       "            <td>3889</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Chicago</td>\n",
       "            <td>3771</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Los_Angeles</td>\n",
       "            <td>937</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Denver</td>\n",
       "            <td>612</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Detroit</td>\n",
       "            <td>262</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Indiana/Indianapolis</td>\n",
       "            <td>151</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Phoenix</td>\n",
       "            <td>100</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Boise</td>\n",
       "            <td>86</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Anchorage</td>\n",
       "            <td>50</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Puerto_Rico</td>\n",
       "            <td>43</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Pacific/Honolulu</td>\n",
       "            <td>34</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Menominee</td>\n",
       "            <td>14</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Nome</td>\n",
       "            <td>12</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Indiana/Vincennes</td>\n",
       "            <td>8</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Kentucky/Louisville</td>\n",
       "            <td>6</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Sitka</td>\n",
       "            <td>6</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Toronto</td>\n",
       "            <td>5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Indiana/Marengo</td>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Indiana/Tell_City</td>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/North_Dakota/Beulah</td>\n",
       "            <td>2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Yakutat</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Indiana/Winamac</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Indiana/Knox</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/North_Dakota/New_Salem</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Indiana/Vevay</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>America/Adak</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+--------------------------------+-------+\n",
       "|            Timezone            | Count |\n",
       "+--------------------------------+-------+\n",
       "|        America/New_York        |  3889 |\n",
       "|        America/Chicago         |  3771 |\n",
       "|      America/Los_Angeles       |  937  |\n",
       "|         America/Denver         |  612  |\n",
       "|        America/Detroit         |  262  |\n",
       "|  America/Indiana/Indianapolis  |  151  |\n",
       "|        America/Phoenix         |  100  |\n",
       "|         America/Boise          |   86  |\n",
       "|       America/Anchorage        |   50  |\n",
       "|      America/Puerto_Rico       |   43  |\n",
       "|        Pacific/Honolulu        |   34  |\n",
       "|       America/Menominee        |   14  |\n",
       "|          America/Nome          |   12  |\n",
       "|   America/Indiana/Vincennes    |   8   |\n",
       "|  America/Kentucky/Louisville   |   6   |\n",
       "|         America/Sitka          |   6   |\n",
       "|        America/Toronto         |   5   |\n",
       "|    America/Indiana/Marengo     |   3   |\n",
       "|   America/Indiana/Tell_City    |   3   |\n",
       "|  America/North_Dakota/Beulah   |   2   |\n",
       "|        America/Yakutat         |   1   |\n",
       "|    America/Indiana/Winamac     |   1   |\n",
       "|      America/Indiana/Knox      |   1   |\n",
       "| America/North_Dakota/New_Salem |   1   |\n",
       "|     America/Indiana/Vevay      |   1   |\n",
       "|          America/Adak          |   1   |\n",
       "+--------------------------------+-------+"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print value counts for Timezone column\n",
    "tz_counts = med_df[\"Timezone\"].value_counts()\n",
    "create_pt(tz_counts, \"Timezone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify datatype Int64 columns\n",
    "\n",
    "- Children\n",
    "- Age\n",
    "-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
